#  First steps -- Loading the training data
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data') #28*28的单色道图像数据

#   Defining our input and output data
""""
MNIST images have a dimension of 28 * 28 pixels with one color channel. 
Our inputs _Xin will be batches of MNIST characters, while our network will learn to reconstruct them 
and output them in a placeholder Y, which thus has the same dimensions. _Yflat will be used later, when 
computing losses. _keepprob will be used when applying dropouts as a means of regularization. 
During training, it will have a value of 0.8. When generating new data, 
we won't apply dropout, so the value will be 1. The function lrelu is being defined as tensorflow 
unfortunately doesn't come up with a predefined leaky ReLU.
""""
tf.reset_default_graph()

batch_size = 64

X_in = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='X')
Y    = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='Y')
Y_flat = tf.reshape(Y, shape=[-1, 28 * 28])  #用于计算损失函数
keep_prob = tf.placeholder(dtype=tf.float32, shape=(), name='keep_prob') #dropout比率

dec_in_channels = 1
n_latent = 8

reshaped_dim = [-1, 7, 7, dec_in_channels]
inputs_decoder = 49 * dec_in_channels / 2


def lrelu(x, alpha=0.3):  #自定义Leaky ReLU函数使效果更好
    return tf.maximum(x, tf.multiply(x, alpha))

#Defining the encoder
""""
As our inputs are images, it's most reasonable to apply some convolutional transformations to them. 
What's most noteworthy is the fact that we are creating two vectors in our encoder, as the encoder is 
supposed to create objects following a Gaussian Distribution:

A vector of means
A vector of standard deviations
You will see later how we "force" the encoder to make sure it really creates values following a Normal 
Distribution. The returned values that will be fed to the decoder are the z-values. We will need the mean 
and standard deviation of our distributions later, when computing losses.
""""


def encoder(X_in, keep_prob): #？？？we use matrix to connect nodes
    activation = lrelu
    with tf.variable_scope("encoder", reuse=None):
        X = tf.reshape(X_in, shape=[-1, 28, 28, 1])
        x = tf.layers.conv2d(X, filters=64, kernel_size=4, strides=2, padding='same', activation=activation)
        x = tf.nn.dropout(x, keep_prob)
        x = tf.layers.conv2d(x, filters=64, kernel_size=4, strides=2, padding='same', activation=activation)
        x = tf.nn.dropout(x, keep_prob)
        x = tf.layers.conv2d(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)
        x = tf.nn.dropout(x, keep_prob)
        x = tf.contrib.layers.flatten(x)
        mn = tf.layers.dense(x, units=n_latent)
        sd = 0.5 * tf.layers.dense(x, units=n_latent)
        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], n_latent]))
        # 从正态分布中采样,creates values following a Normal Distribution
        z = mn + tf.multiply(epsilon, tf.exp(sd))

        return z, mn, sd

# Defining the decoder
""""
The decoder does not care about whether the input values are sampled from some specific 
distribution that has been defined by us. It simply will try to reconstruct the input images. 
To this end, we use a series of transpose convolutions.
""""
def decoder(sampled_z, keep_prob):
    with tf.variable_scope("decoder", reuse=None):
        x = tf.layers.dense(sampled_z, units=inputs_decoder, activation=lrelu)
        x = tf.layers.dense(x, units=inputs_decoder * 2 + 1, activation=lrelu)
        x = tf.reshape(x, reshaped_dim)
        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=4, strides=2, padding='same', activation=tf.nn.relu)
        x = tf.nn.dropout(x, keep_prob)
        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=tf.nn.relu)
        x = tf.nn.dropout(x, keep_prob)
        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=tf.nn.relu)

        x = tf.contrib.layers.flatten(x)
        x = tf.layers.dense(x, units=28 * 28, activation=tf.nn.sigmoid)
        img = tf.reshape(x, shape=[-1, 28, 28])
        return img

# we'll wire together both parts:
sampled, mn, sd = encoder(X_in, keep_prob)
dec = decoder(sampled, keep_prob)

#Computing losses and enforcing a Gaussian latent distribution
"""""
For computing the image reconstruction loss, we simply use squared difference 
(which could lead to images sometimes looking a bit fuzzy). This loss is combined with the
 Kullback-Leibler divergence, which makes sure our latent values will be sampled from a normal 
 distribution. For more on this topic, please take a look a Jaan Altosaar's great article on VAEs.
"""""
unreshaped = tf.reshape(dec, [-1, 28*28])
img_loss = tf.reduce_sum(tf.squared_difference(unreshaped, Y_flat), 1)
# Y_flat = tf.reshape(Y, shape=[-1, 28 * 28]) #用于计算损失函数
#1表示对行元素相加
# D(KL) (q(z|x)||p(z)) = .....
#  -0.5 * (1 + log(sigma**2) - mu**2 - sigma**2)
latent_loss = -0.5 * tf.reduce_sum(1.0 + 2.0 * sd - tf.square(mn) - tf.exp(2.0 * sd), 1)
loss = tf.reduce_mean(img_loss + latent_loss)
optimizer = tf.train.AdamOptimizer(0.0005).minimize(loss)
sess = tf.Session()
sess.run(tf.global_variables_initializer())

# Training the network
"""""
Now, we can finally train our VAE! Every 200 steps, we'll take a look at what the current reconstructions
 look like. After having processed about 2000 batches, most reconstructions will look reasonable.
"""""

for i in range(30000):
    batch = [np.reshape(b, [28, 28]) for b in mnist.train.next_batch(batch_size=batch_size)[0]]
    sess.run(optimizer, feed_dict={X_in: batch, Y: batch, keep_prob: 0.8})

    if not i % 200:
        ls, d, i_ls, d_ls, mu, sigm = sess.run([loss, dec, img_loss, latent_loss, mn, sd],
                                               feed_dict={X_in: batch, Y: batch, keep_prob: 1.0})
        plt.imshow(np.reshape(batch[0], [28, 28]), cmap='gray')
        plt.show()
        plt.imshow(d[0], cmap='gray')
        plt.show()
        print(i, ls, np.mean(i_ls), np.mean(d_ls))
#? plot the previous one and the one learned

# Generating new data
"""""
The most awesome part is that we are now able to create new characters. To this end, we simply sample values
 from a unit normal distribution and feed them to our decoder. Most of the created characters look just like 
 they've been written by humans.
"""""
randoms = [np.random.normal(0, 1, n_latent) for _ in range(10)]
imgs = sess.run(dec, feed_dict = {sampled: randoms, keep_prob: 1.0})
imgs = [np.reshape(imgs[i], [28, 28]) for i in range(len(imgs))]

for img in imgs:
    plt.figure(figsize=(1,1))
    plt.axis('off')
    plt.imshow(img, cmap='gray')

#Conclusion
"""""
Now, this obviously is a relatively simple example of an application of VAEs. 
But just think about what could be possible! Neural networks could learn to compose music. 
They could automatically create illustrations for books, games etc. With a bit of creativity, 
VAEs will open up space for some awesome projects
"""""
